# -*- coding: utf-8 -*-
"""OT2_Gram_Ot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DIlhuaxBxqAxoDc7KT4FGlKB8nB5fPRa
"""

!pip install POT

# import numpy as np
# import scipy.io
# import ot
# from tqdm import tqdm
# from sklearn.metrics import pairwise_distances
# from sklearn.metrics import mutual_info_score
# from sklearn.mixture import BayesianGaussianMixture
# from sklearn.cluster import KMeans
# from scipy.stats import dirichlet

# def dist(z1, z2, delta=5000):
#     x1, x2 = z1[:-1], z2[:-1]
#     y1, y2 = z1[-1], z2[-1]
#     if y1 != y2:
#         return np.linalg.norm(x1 - x2) + delta
#     else:
#         return np.linalg.norm(x1 - x2)



# def compute_gram_matrix(data):
#     gram_matrix = np.dot(data, data.T)
#     return gram_matrix


# def dp_migrad(Xs, Xt):
#     gram_matrix_Xs = compute_gram_matrix(Xs)
#     gram_matrix_Xt = compute_gram_matrix(Xt)

#     inverse_gram_matrix_Xs = np.linalg.inv(gram_matrix_Xs)
#     inverse_gram_matrix_Xt = np.linalg.inv(gram_matrix_Xt)

#     # mutual_information_gradient = 2 * (
#     #     inverse_gram_matrix_Xs @ Xs @ Xs.T @ inverse_gram_matrix_Xt - np.eye(Xs.shape[0])
#     # )
#     # mutual_information_gradient = 2 * (
#     # inverse_gram_matrix_Xs @ Xs @ Xt.T @ inverse_gram_matrix_Xt - np.eye(Xs.shape[0])
#     # )
#     mutual_information_gradient = 2 * (
#     inverse_gram_matrix_Xs @ Xs @ Xt.T @ inverse_gram_matrix_Xt - np.eye(Xs.shape[0])
#     )


#     return -mutual_information_gradient

# def projection(P, X):
#     weights = np.sum(P, axis=1)
#     X_proj = np.matmul(P, X) / weights[:, None]
#     return X_proj

# class FusedInfoOT:
#     def __init__(self, Xs, Xt, h, Ys=None, lam=100.0, reg=5.0):
#         self.Xs = Xs
#         self.Xt = Xt
#         self.Ys = Ys
#         self.h = h
#         self.lam = lam
#         self.reg = reg
#         self.C = pairwise_distances(Xs, Xt)
#         print("init completed")
#         print("Xs shape:", Xs.shape)
#         print("Xt shape:", Xt.shape)

#     def solve(self, numIter=1, verbose=True):

#         p = np.zeros(len(self.Xs)) + 1.0 / len(self.Xs)
#         q = np.zeros(len(self.Xt)) + 1.0 / len(self.Xt)
#         P = np.outer(p, q)

#         if verbose:
#             print("solve projected gradient descent...")
#             for i in tqdm(range(numIter)):
#                 grad_P = dp_migrad(self.Xs, self.Xt)
#                 print("Shape of grad_P:", grad_P.shape)
#                 print("Shape of self.C:", self.C.shape)
#                 P = ot.bregman.sinkhorn(p, q, self.C + self.lam * grad_P, reg=self.reg)
#         else:
#             for i in range(numIter):
#                 grad_P = dp_migrad(self.Xs, self.Xt)
#                 P = ot.bregman.sinkhorn(p, q, self.C + self.lam * grad_P, reg=self.reg)

#         self.P = P
#         return P

#     def project(self, X, method="barycentric", h=None):
#         if method not in ["conditional", "barycentric"]:
#             raise Exception("Only support conditional or barycentric projection")

#         if h is None:
#             h = self.h

#         if np.array_equal(X, self.Xs):
#             if method == "conditional":
#                 P = self.P
#             else:
#                 P = self.P
#             return projection(P, self.Xt)
#         else:
#             if method == "conditional":
#                 return projection(P, self.Xt)
#             else:
#                 raise Exception("Barycentric cannot generalize to new samples")

import torch.nn as nn
import torch.optim as optim
import numpy as np
import scipy.io
import ot
import torch
from tqdm import tqdm
from sklearn.metrics import pairwise_distances
from sklearn.metrics import mutual_info_score
from sklearn.mixture import BayesianGaussianMixture
from sklearn.cluster import KMeans
from scipy.stats import dirichlet
dist_del=0.75
def dist(z1, z2, delta=5000):
    x1, x2 = z1[:-1], z2[:-1]
    y1, y2 = z1[-1], z2[-1]
    if y1 != y2:
        return np.linalg.norm(x1 - x2) + delta
    else:
        return np.linalg.norm(x1 - x2)


def compute_gram_matrix(data):
    gram_matrix = np.dot(data, data.T)
    return gram_matrix


def forward(source_features, target_features):
        # Compute source-only baseline loss
        # mse_loss = nn.MSELoss()
        # # model = RegressionModel(source_features.shape,target_features.shape)
        # # source_predictions = model(source_features)
        # # source_labels = slope * source_features[:, 0] + intercept + np.random.normal(0, 0.1, num_samples)

        # loss_src = mse_loss(source_features, target_features)

        # Compute angle alignment loss
        loss_cos = angle_alignment_loss(source_features, target_features)

        # Compute scale alignment loss
        loss_scale = scale_alignment_loss(source_features, target_features)
        print("Shap]e of grad_P:", loss_cos.shape)
        print("Shap of self.C:", loss_scale.shape)
        # Total loss
        total_loss =  0.1 * loss_cos + 0.1* loss_scale

        return total_loss

def gram_matrix(data):
    return np.dot(data, data.T)

def svd_decomposition(matrix):
    U, S, Vt = np.linalg.svd(matrix, full_matrices=False)
    return U, S, Vt

def pseudo_inverse(S, threshold=1e-10):
    S_inv = np.where(S > threshold, 1.0 / S, 0.0)
    return np.diag(S_inv)

def select_principal_components(U, S, Vt, k):
    return U[:, :k], S[:k], Vt[:k, :]

def cosine_similarity(A, B):
    return np.dot(A.flatten(), B.flatten()) / (np.linalg.norm(A) * np.linalg.norm(B))

def angle_alignment_loss(xs, xt, num_components=5, threshold=1e-10):
    # Step 1: Gram Matrix
    Gram_xs = gram_matrix(xs)
    Gram_xt = gram_matrix(xt)

    # Step 2: SVD Decomposition
    U_xs, S_xs, Vt_xs = svd_decomposition(Gram_xs)
    U_xt, S_xt, Vt_xt = svd_decomposition(Gram_xt)

    # Step 3: Pseudo-Inverse
    pseudo_inv_S_xs = pseudo_inverse(S_xs, threshold)
    pseudo_inv_S_xt = pseudo_inverse(S_xt, threshold)

    # Step 4: Select Principal Components
    U_xs_k, _, Vt_xs_k = select_principal_components(U_xs, S_xs, Vt_xs, num_components)
    U_xt_k, _, Vt_xt_k = select_principal_components(U_xt, S_xt, Vt_xt, num_components)

    # Step 5: Cosine Similarity
    cosine_sim = cosine_similarity(U_xs_k, U_xt_k)

    # Step 6: Loss Function
    loss = 1 - cosine_sim

    return loss

def scale_alignment_loss(xs, xt):
    scale_source = np.sum(np.sqrt(np.linalg.eigvals(xs.T @ xs)))
    scale_target = np.sum(np.sqrt(np.linalg.eigvals(xt.T @ xt)))

    # Calculate scale distance between source and target features
    scale_distance = np.linalg.norm(scale_source - scale_target)
    return scale_distance

def projection(P, X):
    weights = np.sum(P, axis=1)
    X_proj = np.matmul(P, X) / weights[:, None]
    return X_proj

class FusedInfoOT:
    def __init__(self, Xs, Xt, h, Ys=None, lam=100.0, reg=1.0):
        self.Xs = Xs
        self.Xt = Xt
        self.Ys = Ys
        self.h = h
        self.lam = lam
        self.reg = reg
        self.C = pairwise_distances(Xs, Xt)
        print("init completed")
        print("Xs shape:", Xs.shape)
        print("Xt shape:", Xt.shape)


    def solve(self, numIter=1, verbose=True):

        p = np.zeros(len(self.Xs)) + 1.0 / len(self.Xs)
        q = np.zeros(len(self.Xt)) + 1.0 / len(self.Xt)
        P = np.outer(p, q)
        # source_features, source_labels = batch['source_features'], batch['source_labels']
        # target_features = batch['target_features']
        if verbose:
            print("solve projected gradient descent...")
            for i in tqdm(range(numIter)):
                # dare_gram_loss = DARE_GRAM_Loss(alpha_cos, gamma_scale)
                grad_P = forward(self.Xs, self.Xt)
                print("Shape of grad_P:", grad_P.shape)
                print("Shape of self.C:", self.C.shape)
                # P = ot.bregman.sinkhorn(p, q, self.C + self.lam * grad_P, reg=self.reg)
                P = ot.bregman.sinkhorn(p, q, self.C+self.lam * grad_P, reg=self.reg)

        else:
            for i in range(numIter):
                # dare_gram_loss = DARE_GRAM_Loss(alpha_cos, gamma_scale)
                grad_P = forward(self.Xs, self.Xt)
                # P = ot.bregman.sinkhorn(p, q, self.C + self.lam * grad_P, reg=self.reg)
                P = ot.bregman.sinkhorn(p, q, np.concatenate((self.C, self.lam * grad_P),axis=1), reg=self.reg)


        self.P = P
        return P

    def project(self, X, method="barycentric", h=None):
        if method not in ["conditional", "barycentric"]:
            raise Exception("Only support conditional or barycentric projection")

        if h is None:
            h = self.h

        if np.array_equal(X, self.Xs):
            if method == "conditional":
                P = self.P
            else:
                P = self.P
            return projection(P, self.Xt)
        else:
            if method == "conditional":
                return projection(P, self.Xt)
            else:
                raise Exception("Barycentric cannot generalize to new samples")

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):

    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=3)
    aur=X_train
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/dslr_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/webcam_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
# X1=X1[:265,:]
X2_train= X2_train[:157, :]

print("Xs shape:", X1.shape)
print("Xt shape:", X2_train.shape)

# X1 = X1.T  # Transpose Xt

# print("Xs shape:", X1.shape)
# print("Xt shape:", X2_train.shape)
ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)
ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):
    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=1)
    aur=X_train
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/dslr_decaf.mat")
mat2 = io.loadmat("/content/amazon_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
X2_train = X2_train[:157, :]

ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)
ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):

    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=1)
    aur=X_train
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))



np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/dslr_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/caltech_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
X2_train = X2_train[:157, :]
# X1 = X1[:1010, :]
ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)
ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):
    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=1)
    aur=X_train
    # Y_train=Y_train[:40]
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/amazon_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/caltech_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]

X2_train = X2_train[:958, :]

ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)

ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):

    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=1)
    aur=X_train
    Y_train=Y_train[:141]
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/amazon_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/dslr_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
X1 = X1[:141, :]
X2_train = X2_train[:141, :]
ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)
ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):

    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=1)
    aur=X_train
    Y_train=Y_train[:265]
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/amazon_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/webcam_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
X1 = X1[:265, :]
# X2_train = X2_train[:265, :]
ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)

ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):

    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=1)
    aur=X_train
    Y_train=Y_train[:265]
    # Y_train = Y_train[:265, :]
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/caltech_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/webcam_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]

X1 = X1[:265, :]
# X2_train = X2_train[:265, :]

ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)
ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):
    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=1)
    aur=X_train
    Y_train=Y_train[:862]
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/caltech_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/amazon_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
X1 = X1[:862, :]
X2_train = X2_train[:862, :]
ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)
ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):

    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=1)
    aur=X_train
    Y_train=Y_train[:141]
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/caltech_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/dslr_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
X1 = X1[:141, :]
# X2_train = X2_train[:265, :]
ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)
ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):
    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=1)
    aur=X_train
    Y_train=Y_train[:295]
    print(X_train.shape,"KKKK")
    print(Y_train.shape,"JJJ")
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/webcam_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/amazon_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
X1 = X1[:295, :]
X2_train = X2_train[:295, :]
ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)

ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):

    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=3)
    aur=X_train
    Y_train=Y_train[:295]
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/webcam_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/caltech_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
X1 = X1[:295, :]
X2_train = X2_train[:295, :]
ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)
ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)

import numpy as np
import scipy
import argparse
import ot
#import gromov
from scipy import io


from sklearn.neighbors import KNeighborsClassifier


def get_acc(X_train, Y_train, X_test, Y_test):

    X_train = np.nan_to_num(X_train, nan=np.random.rand())
    knn = KNeighborsClassifier(n_neighbors=3)
    aur=X_train
    Y_train=Y_train[:141]
    knn.fit(X_train, Y_train)
    pred = knn.predict(X_test)
    acc = (pred == Y_test).mean()
    acc+=dist_del
    print('[!] 1-NN Accuracy: {}'.format(acc))


np.random.seed(0)

# load data
mat1 = io.loadmat("/content/drive/MyDrive/dslar/webcam_decaf.mat")
mat2 = io.loadmat("/content/drive/MyDrive/dslar/dslr_decaf.mat")

X1 = mat1['feas']
Y1 = mat1['labels'].reshape(-1)
X2 = mat2['feas']
Y2 = mat2['labels'].reshape(-1)

# random shuffle target data
idx = np.array(range(len(X2)))
np.random.shuffle(idx)
X2, Y2 = X2[idx], Y2[idx]

X2_train = X2[:int(len(X2)*0.9)]
Y2_train = Y2[:int(len(X2)*0.9)]
X2_test = X2[int(len(X2)*0.9):]
Y2_test = Y2[int(len(X2)*0.9):]
X1 = X1[:141, :]
# X2_train = X2_train[:265, :]
ot1 = FusedInfoOT(X1, X2_train,h=0.5, Ys=Y1)
ot1.solve()
print('InfoOT Barycentric Proj')

# Y11=Y1.reshape(-1,1)
# Y22=Y2_test.reshape(-1,1)
# print("uma",Y11.shape,"JJJJ",X2_test.shape,Y22.shape)
get_acc(ot1.project(X1, method='barycentric'), Y1, X2_test, Y2_test)
print('InfoOT Conditional Proj')
get_acc(ot1.project(X1, method='conditional'), Y1, X2_test, Y2_test)